[{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"Binary diagnostic tests among commonly used tests medicine used rule certain condition. Commonly, condition disease status, tests may also detect, example, presence bacteria virus, independent clinical manifestations. Test metrics diagnostic accuracies, predictive values likelihood ratios useful tools evaluate efficacy tests comparison gold standard, however, statistics provide description quality test. Performing statistical inference evaluate one test better another simultaneously referencing gold standard complicated. Several authors invested significant effort developing statistical methods perform inference. Understanding implementing methods described statistical literature often far outside comfort zone clinicians, particularly routinely involved academic research. demonstrate implementation testCompareR package.","code":""},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"generating-data","dir":"Articles","previous_headings":"","what":"Generating data","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"package comes data set derived Coronary Artery Surgery Study (cass). dataset looks exercise stress testing history chest pain two tests coronary artery disease determined coronary angiography (gold standard).","code":"dat <- cass"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"using-the-comparer-function","dir":"Articles","previous_headings":"","what":"Using the compareR function","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"testCompareR package elegant simplicity. can pass data compareR() function argument function outputs list object containing results descriptive inferential statistical tests. Individual results can accessed via standard indexing. list output compareR() function useful need manipulate individual outputs subsequent calculations. However, wish see interpretation results, can pass compareR() output interpretR() function. provides results human-readable format. really, ’s ! need know get answers testCompareR. additional functionality might useful know , though.","code":"results <- compareR(dat) #> Warning in validatR(df = df, test1 = test1, test2 = test2, gold = gold): Using default columns. Check test 1 is first column, test 2 is second #>          column and gold standard is third column. results #>      test      metric estimate lower_ci upper_ci   p #> 1  Test 1 Sensitivity     82.6     79.4     85.4     #> 2  Test 2 Sensitivity     91.1     88.6     93.1 *** #> 3  Test 1 Specificity     74.1     68.6     79.1     #> 4  Test 2 Specificity     74.9     69.4     79.8     #> 5  Test 1         PPV     88.1     85.2     90.5     #> 6  Test 2         PPV     89.4     86.7     91.6     #> 7  Test 1         NPV     64.8     59.2     70.0     #> 8  Test 2         NPV     78.5     73.0     83.2 *** #> 9  Test 1         PLR      3.2      2.6      4.0     #> 10 Test 2         PLR      3.6      3.0      4.5     #> 11 Test 1         NLR      0.2      0.2      0.3 *** #> 12 Test 2         NLR      0.1      0.1      0.2     #>  #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 ' ' 1 results$acc$accuracies # returns summary tables for diagnostic accuracies #> $`Test 1` #>             Estimate  SE Lower CI Upper CI #> Sensitivity     82.6 1.5     79.4     85.4 #> Specificity     74.1 2.7     68.6     79.1 #>  #> $`Test 2` #>             Estimate  SE Lower CI Upper CI #> Sensitivity     91.1 1.2     88.6     93.1 #> Specificity     74.9 2.7     69.4     79.8 interpretR(results) #>  #> -------------------------------------------------------------------------------- #> CONTINGENCY TABLES #> -------------------------------------------------------------------------------- #>  #> True Status - POSITIVE #>           Test 2 #> Test 1     Positive Negative #>   Positive      473       29 #>   Negative       81       25 #>  #> True Status - NEGATIVE #>           Test 2 #> Test 1     Positive Negative #>   Positive       22       46 #>   Negative       44      151 #>  #> Gold standard vs. Test 1 #>              Test 1 #> Gold standard Positive Negative #>      Positive      502      106 #>      Negative       68      195 #>  #> Gold standard vs. Test 2 #>              Test 2 #> Gold standard Positive Negative #>      Positive      554       54 #>      Negative       66      197 #>  #> -------------------------------------------------------------------------------- #> PREVALENCE (%) #> -------------------------------------------------------------------------------- #>  #>            Estimate  SE Lower CI Upper CI #> Prevalence     69.8 1.6     66.7     72.8 #>  #> -------------------------------------------------------------------------------- #> DIAGNOSTIC ACCURACIES #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>             Estimate  SE Lower CI Upper CI #> Sensitivity     82.6 1.5     79.4     85.4 #> Specificity     74.1 2.7     68.6     79.1 #>  #>  Test 2 (%) #>             Estimate  SE Lower CI Upper CI #> Sensitivity     91.1 1.2     88.6     93.1 #> Specificity     74.9 2.7     69.4     79.8 #>  #> Global Null Hypothesis: Se1 = Se2 & Sp1 = Sp2 #> Test statistic:  25.662  Adjusted p value:  6.971825e-06 ***SIGNIFICANT*** #>  #> Investigating individual differences #>  #> Null Hypothesis 1: Se1 = Se2 #> Test statistic:  23.64545  Adjusted p value:  6.949149e-06 ***SIGNIFICANT*** #>  #> Null Hypothesis 2: Sp1 = Sp2 #> Test statistic:  0.01111111  Adjusted p value:  1 #>  #> -------------------------------------------------------------------------------- #> PREDICTIVE VALUES #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>     Estimate  SE Lower CI Upper CI #> PPV     88.1 1.4     85.2     90.5 #> NPV     64.8 2.8     59.2     70.0 #>  #>  Test 2 (%) #>     Estimate  SE Lower CI Upper CI #> PPV     89.4 1.2     86.7     91.6 #> NPV     78.5 2.6     73.0     83.2 #>  #> Global Null Hypothesis: PPV1 = PPV2 & NPV1 = NPV2 #> Test statistic:  25.94449  Adjusted p value:  6.971825e-06 ***SIGNIFICANT*** #>  #> Investigating individual differences #>  #> Null Hypothesis 1: PPV1 = PPV2 #> Test statistic:  0.8070579  Adjusted p value:  1 #>  #> Null Hypothesis 2: NPV1 = NPV2 #> Test statistic:  22.50225  Adjusted p value:  1.049486e-05 ***SIGNIFICANT*** #>  #> -------------------------------------------------------------------------------- #> LIKELIHOOD RATIOS #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>     Estimate  SE Lower CI Upper CI #> PLR      3.2 0.3      2.6      4.0 #> NLR      0.2 0.0      0.2      0.3 #>  #>  Test 2 (%) #>     Estimate  SE Lower CI Upper CI #> PLR      3.6 0.4      3.0      4.5 #> NLR      0.1 0.0      0.1      0.2 #>  #> Global Null Hypothesis: PLR1 = PLR2 & NLR1 = NLR2 #> Test statistic:  23.43805  Adjusted p value:  8.137524e-06 ***SIGNIFICANT*** #>  #> Investigating individual differences #>  #> Null Hypothesis 1: PLR1 = PLR2 #> Test statistic:  0.8980246  Adjusted p value:  1 #>  #> Null Hypothesis 2: NLR1 = NLR2 #> Test statistic:  4.662817  Adjusted p value:  1.247637e-05 ***SIGNIFICANT***"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"flexible-input","dir":"Articles","previous_headings":"Using the compareR function","what":"Flexible input","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"compareR() function accept data data frame matrix range coding options positive negative results, detailed . working across multiple sites find researchers used different coding systems, problem! long positive results coded using something positive list negative results something negative list compareR() handle . manually re-coding data! “pesky trailing spaces?” hear ask. course, compareR() can handle , . “Case-sensitivity?” Taken care . POSITIVE: positive, pos, p, yes, y, true, t, +, 1 NEGATIVE: negative, neg, , n, false, f, -, 0, 2 two things compareR() handle. Firstly, imperative data structure provided three columns columns follow pattern Test 1, Test 2, gold standard. place gold standard index your_data[,3] compareR() may return result looks sensible answer question wanted ask. Finally, compareR() handle missing data. Removing missing data option, consider data missing don’t omit write-results. Alternatively, data missing random, consider use imputation methods replace missing data. data missing random imputation becomes vastly complex probably seek expert advice.","code":"# create data frame with varied coding df <- data.frame(   test1 = c(\" positive \", \"POS \", \" n \", \"N \", \" 1 \", \"+\"),   test2 = c(\" NEG \", \" yes \", \" negative\", \" Y \", \"-\", \" 0 \"),   gold = c(0, 1, 0, 1, 2, 1) )  # recode the dataframe recoded <- testCompareR:::recoder(df) recoded #>   test1 test2 gold #> 1     1     0    0 #> 2     1     1    1 #> 3     0     0    0 #> 4     0     1    1 #> 5     1     0    0 #> 6     1     0    1"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"variable-alpha","dir":"Articles","previous_headings":"Using the compareR function","what":"Variable alpha","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"’re using testCompareR ’re statistically savvy want nice function probably just leave alpha alone. good reason, ’re just messing around, feel free change whatever ’d like, though.","code":"# simulate data test1 <- c(rep(1, 300), rep(0, 100), rep(1, 65), rep(0, 135)) test2 <- c(rep(1, 280), rep(0, 120), rep(1, 55), rep(0, 145)) gold <- c(rep(1, 400), rep(0, 200))  df <- data.frame(test1, test2, gold)  # test with alpha = 0.5 result <- compareR(df, alpha = 0.5) #> Warning in validatR(df = df, test1 = test1, test2 = test2, gold = gold): Using default columns. Check test 1 is first column, test 2 is second #>          column and gold standard is third column.  # all results are significant interpretR(result) #>  #> WARNING: #> Zeros exist in contingency table. Tests may return NA/NaN. #>  #> -------------------------------------------------------------------------------- #> CONTINGENCY TABLES #> -------------------------------------------------------------------------------- #>  #> True Status - POSITIVE #>           Test 2 #> Test 1     Positive Negative #>   Positive      280       20 #>   Negative        0      100 #>  #> True Status - NEGATIVE #>           Test 2 #> Test 1     Positive Negative #>   Positive       55       10 #>   Negative        0      135 #>  #> Gold standard vs. Test 1 #>              Test 1 #> Gold standard Positive Negative #>      Positive      300      100 #>      Negative       65      135 #>  #> Gold standard vs. Test 2 #>              Test 2 #> Gold standard Positive Negative #>      Positive      280      120 #>      Negative       55      145 #>  #> -------------------------------------------------------------------------------- #> PREVALENCE (%) #> -------------------------------------------------------------------------------- #>  #>            Estimate  SE Lower CI Upper CI #> Prevalence     66.7 1.9     65.4       68 #>  #> -------------------------------------------------------------------------------- #> DIAGNOSTIC ACCURACIES #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>             Estimate  SE Lower CI Upper CI #> Sensitivity     75.0 2.2     73.5     76.4 #> Specificity     67.5 3.3     65.2     69.7 #>  #>  Test 2 (%) #>             Estimate  SE Lower CI Upper CI #> Sensitivity     70.0 2.3     68.4     71.5 #> Specificity     72.5 3.2     70.3     74.6 #>  #> Global Null Hypothesis: Se1 = Se2 & Sp1 = Sp2 #> Test statistic:  31.57895  Adjusted p value:  4.167158e-07 ***SIGNIFICANT*** #>  #> Investigating individual differences #>  #> Null Hypothesis 1: Se1 = Se2 #> Test statistic:  18.05  Adjusted p value:  0.0001291072 ***SIGNIFICANT*** #>  #> Null Hypothesis 2: Sp1 = Sp2 #> Test statistic:  8.1  Adjusted p value:  0.02213263 ***SIGNIFICANT*** #>  #> -------------------------------------------------------------------------------- #> PREDICTIVE VALUES #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>     Estimate  SE Lower CI Upper CI #> PPV     82.2 2.0     80.8     83.5 #> NPV     57.4 3.2     55.3     59.6 #>  #>  Test 2 (%) #>     Estimate  SE Lower CI Upper CI #> PPV     83.6 2.0     82.2     84.9 #> NPV     54.7 3.1     52.6     56.8 #>  #> Global Null Hypothesis: PPV1 = PPV2 & NPV1 = NPV2 #> Test statistic:  26.92232  Adjusted p value:  2.850504e-06 ***SIGNIFICANT*** #>  #> Investigating individual differences #>  #> Null Hypothesis 1: PPV1 = PPV2 #> Test statistic:  3.171214  Adjusted p value:  0.1498935 ***SIGNIFICANT*** #>  #> Null Hypothesis 2: NPV1 = NPV2 #> Test statistic:  5.653882  Adjusted p value:  0.06966709 ***SIGNIFICANT*** #>  #> -------------------------------------------------------------------------------- #> LIKELIHOOD RATIOS #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>     Estimate  SE Lower CI Upper CI #> PLR      2.3 0.2      2.1      2.5 #> NLR      0.4 0.0      0.3      0.4 #>  #>  Test 2 (%) #>     Estimate  SE Lower CI Upper CI #> PLR      2.5 0.3      2.3      2.7 #> NLR      0.4 0.0      0.4      0.4 #>  #> Global Null Hypothesis: PLR1 = PLR2 & NLR1 = NLR2 #> Test statistic:  23.37068  Adjusted p value:  8.416292e-06 ***SIGNIFICANT*** #>  #> Investigating individual differences #>  #> Null Hypothesis 1: PLR1 = PLR2 #> Test statistic:  1.779904  Adjusted p value:  0.1498935 ***SIGNIFICANT*** #>  #> Null Hypothesis 2: NLR1 = NLR2 #> Test statistic:  2.375766  Adjusted p value:  0.06966709 ***SIGNIFICANT***"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"margins","dir":"Articles","previous_headings":"Using the compareR function","what":"Margins","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"Contingency tables included readout compareR() interpretR(). people like see summed totals columns rows. ’re one people, set margins = TRUE.","code":"# simulate data test1 <- c(rep(1, 300), rep(0, 100), rep(1, 65), rep(0, 135)) test2 <- c(rep(1, 280), rep(0, 120), rep(1, 55), rep(0, 145)) gold <- c(rep(1, 400), rep(0, 200))  df <- data.frame(test1, test2, gold)  # test with alpha = 0.5 result <- compareR(df, margins = TRUE) #> Warning in validatR(df = df, test1 = test1, test2 = test2, gold = gold): Using default columns. Check test 1 is first column, test 2 is second #>          column and gold standard is third column.  # contingency tables have margins result$cont #> $`Gold standard vs. Test 1` #>              Test 1 #> Gold standard Positive Negative Sum #>      Positive      300      100 400 #>      Negative       65      135 200 #>      Sum           365      235 600 #>  #> $`Gold standard vs. Test 2` #>              Test 2 #> Gold standard Positive Negative Sum #>      Positive      280      120 400 #>      Negative       55      145 200 #>      Sum           335      265 600 #>  #> $`True Status: POS` #>           Test 2 #> Test 1     Positive Negative Sum #>   Positive      280       20 300 #>   Negative        0      100 100 #>   Sum           280      120 400 #>  #> $`True Status: NEG` #>           Test 2 #> Test 1     Positive Negative Sum #>   Positive       55       10  65 #>   Negative        0      135 135 #>   Sum            55      145 200"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"multiple-testing","dir":"Articles","previous_headings":"Using the compareR function","what":"Multiple testing","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"default compareR() runs minimum three hypothesis tests can perform nine. accounted using adjusted p-values according Holm method. ’d prefer use different method, ’s problem. Just set multi_corr parameter methods handled base R function p.adjust().","code":"# display p.adjust.methods p.adjust.methods #> [1] \"holm\"       \"hochberg\"   \"hommel\"     \"bonferroni\" \"BH\"         #> [6] \"BY\"         \"fdr\"        \"none\"  # simulate data test1 <- c(rep(1, 300), rep(0, 100), rep(1, 65), rep(0, 135)) test2 <- c(rep(1, 280), rep(0, 120), rep(1, 55), rep(0, 145)) gold <- c(rep(1, 400), rep(0, 200))  df <- data.frame(test1, test2, gold)  # test with different multiple comparison methods result1 <- compareR(df, multi_corr = \"holm\") #> Warning in validatR(df = df, test1 = test1, test2 = test2, gold = gold): Using default columns. Check test 1 is first column, test 2 is second #>          column and gold standard is third column. result2 <- compareR(df, multi_corr = \"bonf\") #> Warning in validatR(df = df, test1 = test1, test2 = test2, gold = gold): Using default columns. Check test 1 is first column, test 2 is second #>          column and gold standard is third column.  # the more restrictive Bonferroni method returns higher adjusted p values result1$pv$glob.p.adj < result2$pv$glob.p.adj #> [1] TRUE"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"continuity-correction","dir":"Articles","previous_headings":"Using the compareR function","what":"Continuity correction","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"certain circumstances compareR() uses McNemar’s test testing differences diagnostic accuracies. test routinely performed continuity correction. wish perform without continuity correction set cc = FALSE. aren’t sure whether run test without continuity correction, stick default parameters.","code":"# simulate data test1 <- c(rep(1, 6), rep(0, 2), rep(1, 14), rep(0, 76)) test2 <- c(rep(1, 1), rep(0, 7), rep(1, 2), rep(0, 88)) gold <- c(rep(1, 8), rep(0, 90))  df <- data.frame(test1, test2, gold)  # run compareR without continuity correction result <- compareR(df, cc = FALSE) #> Warning in validatR(df = df, test1 = test1, test2 = test2, gold = gold): Using default columns. Check test 1 is first column, test 2 is second #>          column and gold standard is third column. result$acc #> $accuracies #> $accuracies$`Test 1` #>             Estimate   SE Lower CI Upper CI #> Sensitivity     75.0 15.3     41.5     93.4 #> Specificity     84.4  3.8     75.7     90.6 #>  #> $accuracies$`Test 2` #>             Estimate   SE Lower CI Upper CI #> Sensitivity     12.5 11.7      1.4     46.2 #> Specificity     97.8  1.6     92.4     99.5 #>  #>  #> $glob.test.stat #> [1] \"n < 100 and prevalence <= 10% - global test not used\" #>  #> $glob.p.value #> [1] NA #>  #> $glob.p.adj #> [1] NA #>  #> $sens.test.stat #> [1] 13.33333 #>  #> $sens.p.value #> [1] NA #>  #> $sens.p.adj #> [1] NA #>  #> $spec.test.stat #> [1] 13.84615 #>  #> $spec.p.value #> [1] NA #>  #> $spec.p.adj #> [1] NA"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"decimal-places","dir":"Articles","previous_headings":"Using the compareR function","what":"Decimal places","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"can change number decimal places displayed summary tables output compareR() interpretR() functions dp parameter. parameter affect number decimal places displayed p values test statistics.","code":"# simulate data test1 <- c(rep(1, 317), rep(0, 83), rep(1, 68), rep(0, 132)) test2 <- c(rep(1, 281), rep(0, 119), rep(1, 51), rep(0, 149)) gold <- c(rep(1, 390), rep(0, 210))  df <- data.frame(test1, test2, gold)  # test with different multiple comparison methods result <- compareR(df, dp = 3) #> Warning in validatR(df = df, test1 = test1, test2 = test2, gold = gold): Using default columns. Check test 1 is first column, test 2 is second #>          column and gold standard is third column.  # the values in the summary tables are displayed to 3 decimal places result$acc$accuracies #> $`Test 1` #>             Estimate    SE Lower CI Upper CI #> Sensitivity   81.282 1.975   77.135   84.863 #> Specificity   67.619 3.229   61.046   73.605 #>  #> $`Test 2` #>             Estimate    SE Lower CI Upper CI #> Sensitivity   72.051 2.272   67.415   76.289 #> Specificity   75.714 2.959   69.520   81.052"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"choosing-your-tests","dir":"Articles","previous_headings":"Using the compareR function","what":"Choosing your tests","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"Another important aspect testCompareR package ability control study design. example, made priori decision interested predictive values, really necessary control multiple tests diagnostic accuracies likelihood ratios? course ! can ask compareR() display results setting parameters pairs tests aren’t interest FALSE. parameters follows: sesp diagnostic accuracies; ppvnpv predictive values; plrnlr likelihood ratios.","code":"# simulate data test1 <- c(rep(1, 317), rep(0, 83), rep(1, 68), rep(0, 132)) test2 <- c(rep(1, 281), rep(0, 119), rep(1, 51), rep(0, 149)) gold <- c(rep(1, 390), rep(0, 210))  df <- data.frame(test1, test2, gold)  # only display results for predictive values result <- compareR(df, test1 = \"test1\", test2 = \"test2\", gold = \"gold\",                     sesp = FALSE, plrnlr = FALSE) result #>     test metric estimate lower_ci upper_ci   p #> 1 Test 1    PPV     82.3     78.2     85.8     #> 2 Test 2    PPV     84.6     80.4     88.1   * #> 3 Test 1    NPV     66.0     59.5     72.1 *** #> 4 Test 2    NPV     59.3     53.4     65.0     #>  #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 ' ' 1"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"test-names","dir":"Articles","previous_headings":"Using the compareR function","what":"Test names","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"want specific test names included output compareR() can set test.names parameter. parameter accepts character vector length 2.","code":"# simulate data test1 <- c(rep(1, 317), rep(0, 83), rep(1, 68), rep(0, 132)) test2 <- c(rep(1, 281), rep(0, 119), rep(1, 51), rep(0, 149)) gold <- c(rep(1, 390), rep(0, 210))  df <- data.frame(test1, test2, gold)  # only display results for predictive values result <- compareR(df, test.names = c(\"POCT\", \"Lab Blood\")) #> Warning in validatR(df = df, test1 = test1, test2 = test2, gold = gold): Using default columns. Check test 1 is first column, test 2 is second #>          column and gold standard is third column. result$acc$accuracies #> $POCT #>             Estimate  SE Lower CI Upper CI #> Sensitivity     81.3 2.0     77.1     84.9 #> Specificity     67.6 3.2     61.0     73.6 #>  #> $`Lab Blood` #>             Estimate  SE Lower CI Upper CI #> Sensitivity     72.1 2.3     67.4     76.3 #> Specificity     75.7 3.0     69.5     81.1"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"made end! pretty well summarises everything need know package. Hopefully save lot time comparing two binary diagnostic tests. Please get touch refinements, comments bugs. source code available Github think can improve !","code":""},{"path":"https://kajlinko.github.io/testCompareR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kyle J. Wilson. Maintainer, author. Marc Henrion. Author. José Antonio Roldán Nofuentes. Author.","code":""},{"path":"https://kajlinko.github.io/testCompareR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wilson K, Henrion M, Roldán Nofuentes J (2024). testCompareR: Comparing Two Diagnostic Tests Dichotomous Results using Paired Data. R package version 1.1.0, https://github.com/Kajlinko/testCompareR, https://kajlinko.github.io/testCompareR/.","code":"@Manual{,   title = {testCompareR: Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data},   author = {Kyle J. Wilson and Marc Henrion and José Antonio {Roldán Nofuentes}},   year = {2024},   note = {R package version 1.1.0, https://github.com/Kajlinko/testCompareR},   url = {https://kajlinko.github.io/testCompareR/}, }"},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"testcomparer","dir":"","previous_headings":"","what":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"Test metrics like sensitivity, specificity, predictive values likelihood ratios common ways measure performance diagnostic test. goal testCompareR make comparing test metrics two diagnostic tests dichotomous outcomes easy. Really easy. want clinical researchers able quickly access statistical methods best performance, without trawl literature learn operate complicated R package. testCompareR hard work don’t .","code":""},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"testCompareR can installed directly CRAN using: can install development version testCompareR GitHub :","code":"install.packages(\"testCompareR\") if (!require(\"devtools\", quietly = TRUE))     install.packages(\"devtools\")  devtools::install_github(\"Kajlinko/testCompareR\")"},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"testCompareR two principal functions: compareR() interpretR(). example simulated data demonstrates work. data provided data frame matrix three columns order test1, test2 gold. sensible code positive negative results systematically, real research can sometimes messy. compareR() function try take care . two function calls can calculate test metrics, including confidence intervals best coverage, compare test metrics using hypothesis tests best asymptotic performance. interpretR() even provides plain English summary results mean console.","code":"library(testCompareR)  # simulate some data test1 <- rep(c(\"positive\", \"pos\", \"p\", \"yes\", \"y\", \"+\", \"1\"), 10) test2 <- rep(c(\"negative\", \"neg\", \"no\", \"n\", \"-\", \"0\", \"2\"), 10) gold <- rep(c(\"positive\", \"pos\", \"p\", \"yes\", \"y\", \"+\", \"1\"), 10)  df <- data.frame(test1, test2, gold)  # run the tests results <- compareR(df)  # interpret the results (optional) interpretR(results)"},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"additional-functions","dir":"","previous_headings":"Examples","what":"Additional functions","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"one test gold standard can summarise descriptive statistics quickly summariseR(). data presented data frame matrix two columns. One final function defined help clinical researchers want perform pooled meta-analysis data already available. dataframeR() constructs data frame can provided compareR() figures commonly quoted literature. dataframeR() eight parameters: s11, s10, s01, s00, r11, r10, r01, r00. Understanding parameter names: s & r represent positive negative results gold standard test, respectively. first digit represents positive (1) negative (0) result Test 1. second digit represents positive (1) negative (0) result Test 2. data frame can combined data frames produce master data frame ready analysis. ideas additional functionality think added, please get touch , better still, make pull request see can code.","code":"library(testCompareR)  # simulate some data test1 <- rep(c(\"positive\", \"pos\", \"p\", \"yes\", \"y\", \"+\", \"1\"), 10) gold <- rep(c(\"positive\", \"pos\", \"p\", \"yes\", \"y\", \"+\", \"1\"), 10)  df <- data.frame(test1, gold)  # run the tests summariseR(df) dataframeR(70, 5, 11, 40, 11, 2, 3, 120)"},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"contributors","dir":"","previous_headings":"","what":"Contributors","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"idea package conceived developed Kyle Wilson. project helped greatly Marc Henrion GitHub. Additionally, statistical methods underlying package source code upon based provided José Antonio Roldán Nofuentes. use package, please consider referencing paper describing statistical methods. paper available .","code":""},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"work licensed General Public License v3.0 (2007). See LICENSE.md details.","code":""},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"Yu, Guo & Xu (2014) JSCS. 2014; 84:5,1022-1038 doi:10.1080/00949655.2012.738211 Martín Andrés & Álvarez Hernández (2014) Stat Comput. 2014; 24,65–75 doi:10.1007/s11222-012-9353-5 Roldán-Nofuentes & Sidaty-Regad (2019) JSCS. 2019; 89:14,2621-2644 doi:10.1080/00949655.2019.1628234 Roldán-Nofuentes, Luna del Castillo & Montero-Alonso (2012) Comput Stat Data Anal. 2012; 6,1161–1173. doi:10.1016/j.csda.2011.06.003 Kosinski (2012) Stat Med. 2012; 32,964-977 doi:10.1002/sim.5587 Roldán-Nofuentes, Luna del Castillo (2007) Stat Med. 2007; 26:4179–201. doi:10.1002/sim.2850 Roldán-Nofuentes (2020) BMC Med Res Methodol. 2020; 20,143 doi:10.1186/s12874-020-00988-y","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cass.html","id":null,"dir":"Reference","previous_headings":"","what":"Coronary Artery Surgery Study data — cass","title":"Coronary Artery Surgery Study data — cass","text":"data Coronary Artery Surgery Study evaluates two tests determine presence absence coronary artery disease comparing coronary angiography, gold standard. Test 1 exercise stress test Test 2 clinical history chest pain.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coronary Artery Surgery Study data — cass","text":"","code":"cass"},{"path":"https://kajlinko.github.io/testCompareR/reference/cass.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Coronary Artery Surgery Study data — cass","text":"data frame 871 rows 3 columns: exercise Dichotomous result exercise stress testing. cp Presence absence chest pain based medical history. angio Dichotomous result coronary angiography.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cass.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Coronary Artery Surgery Study data — cass","text":"doi:10.1056/NEJM197908023010502","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cass.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Coronary Artery Surgery Study data — cass","text":"three variables dichotomous. 1 indicates positive result; 0 indicates negative result. data originally presented Weiner et al. (1979).","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cass.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Coronary Artery Surgery Study data — cass","text":"Weiner et al. (1979)) N Engl J Med. 1979;301(5):230-5 doi:10.1056/NEJM197908023010502","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cfpr.html","id":null,"dir":"Reference","previous_headings":"","what":"US Cystic Fibrosis Patient Registry data — cfpr","title":"US Cystic Fibrosis Patient Registry data — cfpr","text":"data Cystic Fibrosis Foundation's Patient Registry (USA) evaluates risk factors pulmonary exacerbation patients cystic fibrosis. two risk factors evaluated previous pulmonary exacerbation previous colonisation Pseudomonas aeruginosa. two risk factors evaluated using data 1995. instance occurred point 1995 'test' considered positive. negative throughout 1995 'test' considered negative. gold standard evidence pulmonary exacerbation point 1996.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cfpr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"US Cystic Fibrosis Patient Registry data — cfpr","text":"","code":"cfpr"},{"path":"https://kajlinko.github.io/testCompareR/reference/cfpr.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"US Cystic Fibrosis Patient Registry data — cfpr","text":"data frame 11,960 rows 3 columns: pulm.exac Presence absence previous pulmonary exacerbation. pseudomonas Presence absence Pseudomonas aeruginosa   infection. infection Presence absence severe infection (gold standard).","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cfpr.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"US Cystic Fibrosis Patient Registry data — cfpr","text":"Data sourced directly referenced paper. --date data requests contact: Cystic Fibrosis Foundation","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cfpr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"US Cystic Fibrosis Patient Registry data — cfpr","text":"three variables dichotomous. 1 indicates presence; 0 indicates absence. data originally presented Moskowitz Pepe (2006).","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cfpr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"US Cystic Fibrosis Patient Registry data — cfpr","text":"Moskowitz Pepe (2006) Clinical Trials. 2006;3(3):272-9. doi:10.1191/1740774506cn147oa","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":null,"dir":"Reference","previous_headings":"","what":"compareR — compareR","title":"compareR — compareR","text":"Calculates descriptive statistics performs statistical inference two binary diagnostic tests single function call. Handles multiple comparisons using methods `p.adjust()`.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compareR — compareR","text":"","code":"compareR(   df = NULL,   test1 = NULL,   test2 = NULL,   gold = NULL,   alpha = 0.05,   margins = FALSE,   multi_corr = \"holm\",   cc = TRUE,   dp = 1,   sesp = TRUE,   ppvnpv = TRUE,   plrnlr = TRUE,   conf.int = \"contemporary\",   test.names = c(\"Test 1\", \"Test 2\"),   ... )"},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"compareR — compareR","text":"df data frame matrix 3 columns (test1, test2, gold). Flexible coding positive negative results permitted. test1 Either vector values Test 1 (df NULL) string integer value used subsetting df. test2 Either vector values Test 2 (df NULL) string integer value used subsetting df. gold Either vector values gold standard test (df NULL) string integer value used subsetting df. alpha alpha value. Defaults 0.05. margins Boolean value indicating whether contingency tables margins containing summed totals rows columns. multi_corr Method multiple comparisons. Uses `p.adjust.methods`. cc Boolean value indicating whether McNemar's test applied continuity correction. dp Number decimal places output summary tables. Defaults 1. sesp Boolean value indicating whether output include sensitivity specificity. ppvnpv Boolean value indicating whether output include positive negative predictive values. plrnlr Boolean value indicating whether output include positive negative likelihood ratios. conf.int character string, either \"contemporary\" \"classic\". Indicates whether function use contemporary classic statistical methods calculate confidence intervals. test.names vector length two giving names two different binary diagnostic tests. argument relevant testing single binary diagnostic test. ... Rarely needs used. Allows additional arguments passed internal functions.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"compareR — compareR","text":"list object summarising calculated descriptive inferential statistics.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"compareR — compareR","text":"Confidence intervals prevalence, diagnostic accuracies predictive values calculated using interval binomial proportions described Yu et al. (2014) default. Setting conf.int = \"classic\" uses Clopper-Pearson method. Confidence intervals likelihood ratios calculated using methods recommended Martín-Andrés Álvarez-Hernández (2014). Hypothesis testing diagnostic accuracies uses different methods depending disease prevalence number participants samples described Roldán-Nofuentes Sidaty-Regad (2019). Global hypothesis testing predictive values uses method described Roldán-Nofuentes et al. (2012), subsequent individual tests (indicated) performed using methods described Kosinksi (2012). methods hypothesis testing- likelihood ratios taken Roldán-Nofuentes & Luna del Castillo (2007). excellent summary methods provided Roldán-Nofuentes (2020) along open-source program (compbdt) licensed GPL-2. R package can considered extension work therefore distributed license. Please consider citing Roldán-Nofuentes (2020) citing package.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"compareR — compareR","text":"Yu, Guo & Xu (2014) JSCS. 2014; 84:5,1022-1038 doi:10.1080/00949655.2012.738211 Clopper & Pearson (1934) Biometrika. 1934; 26,404-413 doi:10.2307/2331986 Martín Andrés & Álvarez Hernández (2014) Stat Comput. 2014; 24,65–75 doi:10.1007/s11222-012-9353-5 Roldán-Nofuentes & Sidaty-Regad (2019) JSCS. 2019; 89:14,2621-2644 doi:10.1080/00949655.2019.1628234 Roldán-Nofuentes, Luna del Castillo & Montero-Alonso (2012) Comput Stat Data Anal. 2012; 6,1161–1173. doi:10.1016/j.csda.2011.06.003 Kosinski (2012) Stat Med. 2012; 32,964-977 doi:10.1002/sim.5587 Roldán-Nofuentes, Luna del Castillo (2007) Stat Med. 2007; 26:4179–201. doi:10.1002/sim.2850 Roldán-Nofuentes (2020) BMC Med Res Methodol. 2020; 20,143 doi:10.1186/s12874-020-00988-y","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"compareR — compareR","text":"","code":"# load data df <- cfpr  # run compareR function compareR(df,   margins = TRUE, multi_corr = \"bonf\",   test.names = c(\"pulm.exac\", \"pseudomonas\") ) #> Warning: Using default columns. Check test 1 is first column, test 2 is second #>          column and gold standard is third column. #>           test      metric estimate lower_ci upper_ci   p #> 1    pulm.exac Sensitivity     71.8     70.6     73.0 *** #> 2  pseudomonas Sensitivity      3.7      3.2      4.2     #> 3    pulm.exac Specificity     80.6     79.6     81.5     #> 4  pseudomonas Specificity     98.2     97.9     98.5 *** #> 5    pulm.exac         PPV     73.0     71.8     74.2 *** #> 6  pseudomonas         PPV     60.1     54.5     65.4     #> 7    pulm.exac         NPV     79.6     78.7     80.6 *** #> 8  pseudomonas         NPV     58.2     57.3     59.1     #> 9    pulm.exac         PLR      3.7      3.5      3.9 *** #> 10 pseudomonas         PLR      2.1      1.6      2.6     #> 11   pulm.exac         NLR      0.3      0.3      0.4     #> 12 pseudomonas         NLR      1.0      1.0      1.0 *** #>  #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 ' ' 1"},{"path":"https://kajlinko.github.io/testCompareR/reference/dataframeR.html","id":null,"dir":"Reference","previous_headings":"","what":"dataframeR — dataframeR","title":"dataframeR — dataframeR","text":"Produces data frame can used compareR function using values commonly found published literature. Useful reviews meta-analyses.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/dataframeR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dataframeR — dataframeR","text":"","code":"dataframeR(s11, s10, s01, s00, r11, r10, r01, r00)"},{"path":"https://kajlinko.github.io/testCompareR/reference/dataframeR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dataframeR — dataframeR","text":"s11 Number cases Test 1 positive, Test 2 positive gold standard positive. s10 Number cases Test 1 positive, Test 2 negative gold standard positive. s01 Number cases Test 1 negative, Test 2 positive gold standard positive. s00 Number cases Test 1 negative, Test 2 negative gold standard positive. r11 Number cases Test 1 positive, Test 2 positive gold standard negative. r10 Number cases Test 1 positive, Test 2 negative gold standard negative. r01 Number cases Test 1 negative, Test 2 positive gold standard negative. r00 Number cases Test 1 negative, Test 2 negative gold standard negative.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/dataframeR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dataframeR — dataframeR","text":"data frame populated zeros ones indicating positive negative test results can passed compareR function.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/dataframeR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"dataframeR — dataframeR","text":"Understanding parameter names: s & r represent positive negative results gold standard test, respectively. first digit represents positive (1) negative (0) result Test 1. second digit represents positive (1) negative (0) result Test 2.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/dataframeR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"dataframeR — dataframeR","text":"","code":"# build data frame using numbers dataframeR(3, 3, 3, 3, 3, 3, 3, 3) #>    test1 test2 gold #> 1      1     1    1 #> 2      1     1    1 #> 3      1     1    1 #> 4      1     0    1 #> 5      1     0    1 #> 6      1     0    1 #> 7      0     1    1 #> 8      0     1    1 #> 9      0     1    1 #> 10     0     0    1 #> 11     0     0    1 #> 12     0     0    1 #> 13     1     1    0 #> 14     1     1    0 #> 15     1     1    0 #> 16     1     0    0 #> 17     1     0    0 #> 18     1     0    0 #> 19     0     1    0 #> 20     0     1    0 #> 21     0     1    0 #> 22     0     0    0 #> 23     0     0    0 #> 24     0     0    0"},{"path":"https://kajlinko.github.io/testCompareR/reference/interpretR.html","id":null,"dir":"Reference","previous_headings":"","what":"interpretR — interpretR","title":"interpretR — interpretR","text":"Provides plain English readout results compareR function.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/interpretR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"interpretR — interpretR","text":"","code":"interpretR(result)"},{"path":"https://kajlinko.github.io/testCompareR/reference/interpretR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"interpretR — interpretR","text":"result list object class 'compareR' output compareR function.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/interpretR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"interpretR — interpretR","text":"plain English summary findings produced compareR function.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/interpretR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"interpretR — interpretR","text":"","code":"# simulate data test1 <- c(rep(1, 300), rep(0, 100), rep(1, 55), rep(0, 145)) test2 <- c(rep(1, 280), rep(0, 120), rep(1, 45), rep(0, 155)) gold <- c(rep(1, 400), rep(0, 200)) dat <- data.frame(test1, test2, gold)  # compare with compareR result <- compareR(dat) #> Warning: Using default columns. Check test 1 is first column, test 2 is second #>          column and gold standard is third column.  # provide a plain English readout with interpretR interpretR(result) #>  #> WARNING: #> Zeros exist in contingency table. Tests may return NA/NaN. #>  #> -------------------------------------------------------------------------------- #> CONTINGENCY TABLES #> -------------------------------------------------------------------------------- #>  #> True Status - POSITIVE #>           Test 2 #> Test 1     Positive Negative #>   Positive      280       20 #>   Negative        0      100 #>  #> True Status - NEGATIVE #>           Test 2 #> Test 1     Positive Negative #>   Positive       45       10 #>   Negative        0      145 #>  #> Gold standard vs. Test 1 #>              Test 1 #> Gold standard Positive Negative #>      Positive      300      100 #>      Negative       55      145 #>  #> Gold standard vs. Test 2 #>              Test 2 #> Gold standard Positive Negative #>      Positive      280      120 #>      Negative       45      155 #>  #> -------------------------------------------------------------------------------- #> PREVALENCE (%) #> -------------------------------------------------------------------------------- #>  #>            Estimate  SE Lower CI Upper CI #> Prevalence     66.7 1.9     62.8     70.3 #>  #> -------------------------------------------------------------------------------- #> DIAGNOSTIC ACCURACIES #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>             Estimate  SE Lower CI Upper CI #> Sensitivity     75.0 2.2     70.5     79.0 #> Specificity     72.5 3.2     66.0     78.3 #>  #>  Test 2 (%) #>             Estimate  SE Lower CI Upper CI #> Sensitivity     70.0 2.3     65.4     74.3 #> Specificity     77.5 3.0     71.3     82.8 #>  #> Global Null Hypothesis: Se1 = Se2 & Sp1 = Sp2 #> Test statistic:  31.57895  Adjusted p value:  4.167158e-07 ***SIGNIFICANT*** #>  #> Investigating individual differences #>  #> Null Hypothesis 1: Se1 = Se2 #> Test statistic:  18.05  Adjusted p value:  0.0001291072 ***SIGNIFICANT*** #>  #> Null Hypothesis 2: Sp1 = Sp2 #> Test statistic:  8.1  Adjusted p value:  0.02213263 ***SIGNIFICANT*** #>  #> -------------------------------------------------------------------------------- #> PREDICTIVE VALUES #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>     Estimate  SE Lower CI Upper CI #> PPV     84.5 1.9     80.4     87.9 #> NPV     59.2 3.1     52.9     65.2 #>  #>  Test 2 (%) #>     Estimate  SE Lower CI Upper CI #> PPV     86.2 1.9     82.0     89.5 #> NPV     56.4 3.0     50.5     62.1 #>  #> Global Null Hypothesis: PPV1 = PPV2 & NPV1 = NPV2 #> Test statistic:  28.43169  Adjusted p value:  1.340192e-06 ***SIGNIFICANT*** #>  #> Investigating individual differences #>  #> Null Hypothesis 1: PPV1 = PPV2 #> Test statistic:  4.059529  Adjusted p value:  0.08784551 #>  #> Null Hypothesis 2: NPV1 = NPV2 #> Test statistic:  6.343355  Adjusted p value:  0.04712873 ***SIGNIFICANT*** #>  #> -------------------------------------------------------------------------------- #> LIKELIHOOD RATIOS #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>     Estimate  SE Lower CI Upper CI #> PLR      2.7 0.3      2.2      3.5 #> NLR      0.3 0.0      0.3      0.4 #>  #>  Test 2 (%) #>     Estimate  SE Lower CI Upper CI #> PLR      3.1 0.4      2.4      4.1 #> NLR      0.4 0.0      0.3      0.5 #>  #> Global Null Hypothesis: PLR1 = PLR2 & NLR1 = NLR2 #> Test statistic:  24.2216  Adjusted p value:  5.499788e-06 ***SIGNIFICANT*** #>  #> Investigating individual differences #>  #> Null Hypothesis 1: PLR1 = PLR2 #> Test statistic:  2.013107  Adjusted p value:  0.08784551 #>  #> Null Hypothesis 2: NLR1 = NLR2 #> Test statistic:  2.516314  Adjusted p value:  0.04712873 ***SIGNIFICANT***"},{"path":"https://kajlinko.github.io/testCompareR/reference/plot.compareR.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot a compareR object — plot.compareR","title":"Plot a compareR object — plot.compareR","text":"S3 method plot simple visualisation results compareR function.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/plot.compareR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot a compareR object — plot.compareR","text":"","code":"# S3 method for class 'compareR' plot(x, ...)"},{"path":"https://kajlinko.github.io/testCompareR/reference/plot.compareR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot a compareR object — plot.compareR","text":"x object class compareR. ... Arguments graphical parameters. currently use.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/plot.compareR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot a compareR object — plot.compareR","text":"visualisation results diagnostic accuracies predictive values compareR output.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/plot.compareR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot a compareR object — plot.compareR","text":"Method plot commonly used results compareR output.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/plot.compareR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot a compareR object — plot.compareR","text":"","code":"# generate result res <- compareR(cass, test1 = \"exercise\", test2 = \"cp\",                 gold = \"angio\",                 test.names = c(\"ExerciseStressTest\", \"ChestPain\"))  # run print method plot(res)"},{"path":"https://kajlinko.github.io/testCompareR/reference/print.compareR.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a compareR object — print.compareR","title":"Print a compareR object — print.compareR","text":"S3 method print results verbose compareR function.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/print.compareR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a compareR object — print.compareR","text":"","code":"# S3 method for class 'compareR' print(x, ...)"},{"path":"https://kajlinko.github.io/testCompareR/reference/print.compareR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a compareR object — print.compareR","text":"x object class compareR. ... arguments passed methods.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/print.compareR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Print a compareR object — print.compareR","text":"printed results table compareR output.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/print.compareR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Print a compareR object — print.compareR","text":"Method print pertinent results compareR output.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/print.compareR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Print a compareR object — print.compareR","text":"","code":"# generate result res <- compareR(cass, test1 = \"exercise\", test2 = \"cp\",                 gold = \"angio\",                 test.names = c(\"ExerciseStressTest\", \"ChestPain\"))  # run print method print(res) #>                  test      metric estimate lower_ci upper_ci   p #> 1  ExerciseStressTest Sensitivity     82.6     79.4     85.4     #> 2           ChestPain Sensitivity     91.1     88.6     93.1 *** #> 3  ExerciseStressTest Specificity     74.1     68.6     79.1     #> 4           ChestPain Specificity     74.9     69.4     79.8     #> 5  ExerciseStressTest         PPV     88.1     85.2     90.5     #> 6           ChestPain         PPV     89.4     86.7     91.6     #> 7  ExerciseStressTest         NPV     64.8     59.2     70.0     #> 8           ChestPain         NPV     78.5     73.0     83.2 *** #> 9  ExerciseStressTest         PLR      3.2      2.6      4.0     #> 10          ChestPain         PLR      3.6      3.0      4.5     #> 11 ExerciseStressTest         NLR      0.2      0.2      0.3 *** #> 12          ChestPain         NLR      0.1      0.1      0.2     #>  #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 ' ' 1"},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":null,"dir":"Reference","previous_headings":"","what":"summariseR — summariseR","title":"summariseR — summariseR","text":"Summarises descriptive statistics associated single binary diagnostic test.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summariseR — summariseR","text":"","code":"summariseR(df, dp = 1)"},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summariseR — summariseR","text":"df data frame matrix 2 columns (test1, gold). Flexible coding positive negative results permitted. dp Number decimal places output summary tables. Defaults 1. Kappa defaults 3 decimal places unless user selects .","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summariseR — summariseR","text":"summary descriptive statistics binary diagnostic test, compared gold standard.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"summariseR — summariseR","text":"Confidence intervals prevalence, diagnostic accuracies predictive values calculated using interval binomial proportions described Yu et al. (2014). Confidence intervals likelihood ratios calculated using methods recommended Martín-Andrés Álvarez-Hernández (2014). Cohen's kappa value -1 1 describes agreement two tests, taking account random agreement. score zero less indicates agreement entirely due chance.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"summariseR — summariseR","text":"Yu, Guo & Xu (2014) JSCS. 2014; 84:5,1022-1038 doi:10.1080/00949655.2012.738211 Martín Andrés & Álvarez Hernández (2014) Stat Comput. 2014; 24,65–75 doi:10.1007/s11222-012-9353-5 Cohen (1960) Educ Psychol Meas. 1960; 20(1),37–46 doi:10.1177/001316446002000104","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"summariseR — summariseR","text":"","code":"# simulate data test1 <- c(rep(1, 300), rep(0, 100), rep(1, 55), rep(0, 145)) gold <- c(rep(1, 400), rep(0, 200)) dat <- data.frame(test1, gold)  # summarise descriptive statistics result <- summariseR(dat, dp = 4)"},{"path":"https://kajlinko.github.io/testCompareR/reference/summary.compareR.html","id":null,"dir":"Reference","previous_headings":"","what":"Summarise a compareR object — summary.compareR","title":"Summarise a compareR object — summary.compareR","text":"S3 method summarise rather verbose output compareR function.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summary.compareR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Summarise a compareR object — summary.compareR","text":"","code":"# S3 method for class 'compareR' summary(object, ...)"},{"path":"https://kajlinko.github.io/testCompareR/reference/summary.compareR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Summarise a compareR object — summary.compareR","text":"object object class compareR. ... Additional arguments affecting summary produced.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summary.compareR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Summarise a compareR object — summary.compareR","text":"summary compareR output.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summary.compareR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Summarise a compareR object — summary.compareR","text":"Method summarise verbose compareR output.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summary.compareR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Summarise a compareR object — summary.compareR","text":"","code":"# generate result res <- compareR(cass, test1 = \"exercise\", test2 = \"cp\",                 gold = \"angio\",                 test.names = c(\"ExerciseStressTest\", \"ChestPain\"))  # run summary method summary(res) #> Comparison of two binary diagnostic tests using paired data #>  #> Test 1: ExerciseStressTest  Test 2: ChestPain  #>  #> Contingency tables: #>  #>              Test 1 #> Gold standard Positive Negative #>      Positive      502      106 #>      Negative       68      195 #>  #>              Test 2 #> Gold standard Positive Negative #>      Positive      554       54 #>      Negative       66      197 #>  #> Summary of comparisons: #>  #>      test      metric estimate lower_ci upper_ci   p #> 1  Test 1 Sensitivity     82.6     79.4     85.4     #> 2  Test 2 Sensitivity     91.1     88.6     93.1 *** #> 3  Test 1 Specificity     74.1     68.6     79.1     #> 4  Test 2 Specificity     74.9     69.4     79.8     #> 5  Test 1         PPV     88.1     85.2     90.5     #> 6  Test 2         PPV     89.4     86.7     91.6     #> 7  Test 1         NPV     64.8     59.2     70.0     #> 8  Test 2         NPV     78.5     73.0     83.2 *** #> 9  Test 1         PLR      3.2      2.6      4.0     #> 10 Test 2         PLR      3.6      3.0      4.5     #> 11 Test 1         NLR      0.2      0.2      0.3 *** #> 12 Test 2         NLR      0.1      0.1      0.2     #>  #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 ' ' 1"},{"path":"https://kajlinko.github.io/testCompareR/news/index.html","id":"testcomparer-110","dir":"Changelog","previous_headings":"","what":"testCompareR 1.1.0","title":"testCompareR 1.1.0","text":"CRAN release: 2024-10-02 Added generic functions - summary(), print() plot() Fixed broken tests Updated arguments remove ambiguity Added validatR function checking new arguments","code":""},{"path":"https://kajlinko.github.io/testCompareR/news/index.html","id":"testcomparer-104","dir":"Changelog","previous_headings":"","what":"testCompareR 1.0.4","title":"testCompareR 1.0.4","text":"CRAN release: 2024-09-17 Updated error message sesp, ppvnpv plrnlr FALSE clarity","code":""},{"path":"https://kajlinko.github.io/testCompareR/news/index.html","id":"testcomparer-103","dir":"Changelog","previous_headings":"","what":"testCompareR 1.0.3","title":"testCompareR 1.0.3","text":"CRAN release: 2024-04-30 Fixed bugs arising amended p value calculations Updated README.md Updated Using testCompareR vignette","code":""},{"path":"https://kajlinko.github.io/testCompareR/news/index.html","id":"testcomparer-102","dir":"Changelog","previous_headings":"","what":"testCompareR 1.0.2","title":"testCompareR 1.0.2","text":"CRAN release: 2023-09-15 Finalised corrections p value calculations updated package tests Changed license GPL3 conform CRAN","code":""},{"path":"https://kajlinko.github.io/testCompareR/news/index.html","id":"testcomparer-101","dir":"Changelog","previous_headings":"","what":"testCompareR 1.0.1","title":"testCompareR 1.0.1","text":"Updated Roldán-Nofuentes’ role author Updated p value calculations correct formula Updated license GPL3+ (written permission JARN)","code":""},{"path":"https://kajlinko.github.io/testCompareR/news/index.html","id":"testcomparer-100","dir":"Changelog","previous_headings":"","what":"testCompareR 1.0.0","title":"testCompareR 1.0.0","text":"CRAN release: 2023-06-27 Submitted CRAN","code":""},{"path":"https://kajlinko.github.io/testCompareR/news/index.html","id":"testcomparer-010","dir":"Changelog","previous_headings":"","what":"testCompareR 0.1.0","title":"testCompareR 0.1.0","text":"Added NEWS.md file track changes package. Validated statistical methods alternatives (DTComPair package) compbdt program Prepared submission CRAN","code":""}]

[{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"Binary diagnostic tests among commonly used tests medicine used rule certain condition. Commonly, condition disease status, tests may also detect, example, presence bacteria virus, independent clinical manifestations. Test metrics diagnostic accuracies, predictive values likelihood ratios useful tools evaluate efficacy tests comparison gold standard, however, statistics provide description quality test. Performing statistical inference evaluate one test better another simultaneously referencing gold standard complicated. Several authors invested significant effort developing statistical methods perform inference. Understanding implementing methods described statistical literature often far outside comfort zone clinicians, particularly routinely involved academic research. demonstrate implementation testCompareR package.","code":""},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"generating-data","dir":"Articles","previous_headings":"","what":"Generating data","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"package comes data set derived Cystic Fibrosis Patient Registry. data originally presented paper ‘Comparing predictive values diagnostic tests: sample size analysis paired study designs’ Moskowitz Pepe. Two binary prognostic factors evaluated predictors severe infection cystic fibrosis patients.","code":"dat <- cfpr"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"using-the-comparer-function","dir":"Articles","previous_headings":"","what":"Using the compareR function","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"testCompareR package elegant simplicity. can pass data compareR() function argument function outputs list object containing results descriptive inferential statistical tests. Individual results can accessed via standard indexing. list output compareR() function useful need manipulate individual outputs subsequent calculations. However, wish see interpretation results, can pass compareR output interpretR() function. provides results human-readable format. really, ’s ! need know get answers testCompareR. additional functionality might useful know , though.","code":"results <- compareR(dat) results #> $cont #> $cont$`True Status: POS` #>           Test 2 #> Test 1     Positive Negative #>   Positive      185     3445 #>   Negative        0     1424 #>  #> $cont$`True Status: NEG` #>           Test 2 #> Test 1     Positive Negative #>   Positive      123     1219 #>   Negative        0     5564 #>  #>  #> $prev #>            Estimate  SE Lower CI Upper CI #> Prevalence     42.3 0.5     41.4     43.1 #>  #> $acc #> $acc$accuracies #> $acc$accuracies$`Test 1` #>             Estimate  SE Lower CI Upper CI #> Sensitivity     71.8 0.6     70.6     73.0 #> Specificity     80.6 0.5     79.6     81.5 #>  #> $acc$accuracies$`Test 2` #>             Estimate  SE Lower CI Upper CI #> Sensitivity      3.7 0.3      3.2      4.2 #> Specificity     98.2 0.2     97.9     98.5 #>  #>  #> $acc$glob.test.stat #> [1] 12301.32 #>  #> $acc$glob.p.value #> [1] 0 #>  #> $acc$glob.p.adj #> [1] 0 #>  #> $acc$sens.test.stat #> [1] 10821.03 #>  #> $acc$sens.p.value #> [1] 0 #>  #> $acc$sens.p.adj #> [1] 0 #>  #> $acc$spec.test.stat #> [1] 1480.291 #>  #> $acc$spec.p.value #> [1] 0 #>  #> $acc$spec.p.adj #> [1] 0 #>  #>  #> $pv #> $pv$predictive.values #> $pv$predictive.values$`Test 1` #>     Estimate  SE Lower CI Upper CI #> PPV     73.0 0.6     71.8     74.2 #> NPV     79.6 0.5     78.7     80.6 #>  #> $pv$predictive.values$`Test 2` #>     Estimate  SE Lower CI Upper CI #> PPV     60.1 2.8     54.5     65.4 #> NPV     58.2 0.5     57.3     59.1 #>  #>  #> $pv$glob.test.stat #> [1] 2830.026 #>  #> $pv$glob.p.value #> [1] 0 #>  #> $pv$glob.p.adj #> [1] 0 #>  #> $pv$ppv.test.stat #> [1] 28.45746 #>  #> $pv$ppv.p.value #> [1] 9.578013e-08 #>  #> $pv$ppv.p.adj #> [1] 1.915603e-07 #>  #> $pv$npv.test.stat #> [1] 2261.186 #>  #> $pv$npv.p.value #> [1] 0 #>  #> $pv$npv.p.adj #> [1] 0 #>  #>  #> $lr #> $lr$likelihood.ratios #> $lr$likelihood.ratios$`Test 1` #>     Estimate  SE Lower CI Upper CI #> PLR      3.7 0.1      3.5      3.9 #> NLR      0.3 0.0      0.3      0.4 #>  #> $lr$likelihood.ratios$`Test 2` #>     Estimate  SE Lower CI Upper CI #> PLR      2.1 0.2      1.6      2.6 #> NLR      1.0 0.0      1.0      1.0 #>  #>  #> $lr$glob.test.stat #> [1] 2010.219 #>  #> $lr$glob.p.value #> [1] 0 #>  #> $lr$glob.p.adj #> [1] 0 #>  #> $lr$plr.test.stat #> [1] 5.246279 #>  #> $lr$plr.p.value #> [1] 1.552014e-07 #>  #> $lr$plr.p.adj #> [1] 1.915603e-07 #>  #> $lr$nlr.test.stat #> [1] 44.83283 #>  #> $lr$nlr.p.value #> [1] 0 #>  #> $lr$nlr.p.adj #> [1] 0 #>  #>  #> $other #> $other$alpha #> [1] 0.05 #>  #> $other$equal #> [1] FALSE #>  #> $other$zeros #> [1] 2 #>  #> $other$Youden1 #> [1] 0.5239192 #>  #> $other$Youden2 #> [1] 0.01879407 #>  #> $other$test.names #> [1] \"Test 1\" \"Test 2\" #>  #>  #> attr(,\"class\") #> [1] \"compareR\" results$acc$accuracies # returns summary tables for diagnostic accuracies #> $`Test 1` #>             Estimate  SE Lower CI Upper CI #> Sensitivity     71.8 0.6     70.6     73.0 #> Specificity     80.6 0.5     79.6     81.5 #>  #> $`Test 2` #>             Estimate  SE Lower CI Upper CI #> Sensitivity      3.7 0.3      3.2      4.2 #> Specificity     98.2 0.2     97.9     98.5 interpretR(results) #>  #> WARNING: #> Zeros exist in contingency table. Tests may return NA/NaN. #>  #> -------------------------------------------------------------------------------- #> CONTINGENCY TABLES #> -------------------------------------------------------------------------------- #>  #> True Status - POSITIVE #>           Test 2 #> Test 1     Positive Negative #>   Positive      185     3445 #>   Negative        0     1424 #>  #> True Status - NEGATIVE #>           Test 2 #> Test 1     Positive Negative #>   Positive      123     1219 #>   Negative        0     5564 #>  #> -------------------------------------------------------------------------------- #> PREVALENCE (%) #> -------------------------------------------------------------------------------- #>  #>            Estimate  SE Lower CI Upper CI #> Prevalence     42.3 0.5     41.4     43.1 #>  #> -------------------------------------------------------------------------------- #> DIAGNOSTIC ACCURACIES #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>             Estimate  SE Lower CI Upper CI #> Sensitivity     71.8 0.6     70.6     73.0 #> Specificity     80.6 0.5     79.6     81.5 #>  #>  Test 2 (%) #>             Estimate  SE Lower CI Upper CI #> Sensitivity      3.7 0.3      3.2      4.2 #> Specificity     98.2 0.2     97.9     98.5 #>  #> Global Null Hypothesis: Se1 = Se2 & Sp1 = Sp2 #> Test statistic:  12301.32  Adjusted p value:  0 ***SIGNIFICANT*** #>  #> Investigating cause(s) of significance #>  #> Null Hypothesis 1: Se1 = Se2 #> Test statistic:  10821.03  Adjusted p value:  0 ***SIGNIFICANT*** #>  #> Null Hypothesis 2: Sp1 = Sp2 #> Test statistic:  1480.291  Adjusted p value:  0 ***SIGNIFICANT*** #>  #> -------------------------------------------------------------------------------- #> PREDICTIVE VALUES #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>     Estimate  SE Lower CI Upper CI #> PPV     73.0 0.6     71.8     74.2 #> NPV     79.6 0.5     78.7     80.6 #>  #>  Test 2 (%) #>     Estimate  SE Lower CI Upper CI #> PPV     60.1 2.8     54.5     65.4 #> NPV     58.2 0.5     57.3     59.1 #>  #> Global Null Hypothesis: PPV1 = PPV2 & NPV1 = NPV2 #> Test statistic:  2830.026  Adjusted p value:  0 ***SIGNIFICANT*** #>  #> Investigating cause(s) of significance #>  #> Null Hypothesis 1: PPV1 = PPV2 #> Test statistic:  28.45746  Adjusted p value:  1.915603e-07 ***SIGNIFICANT*** #>  #> Null Hypothesis 2: NPV1 = NPV2 #> Test statistic:  2261.186  Adjusted p value:  0 ***SIGNIFICANT*** #>  #> -------------------------------------------------------------------------------- #> LIKELIHOOD RATIOS #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>     Estimate  SE Lower CI Upper CI #> PLR      3.7 0.1      3.5      3.9 #> NLR      0.3 0.0      0.3      0.4 #>  #>  Test 2 (%) #>     Estimate  SE Lower CI Upper CI #> PLR      2.1 0.2      1.6      2.6 #> NLR      1.0 0.0      1.0      1.0 #>  #> Global Null Hypothesis: PLR1 = PLR2 & NLR1 = NLR2 #> Test statistic:  2010.219  Adjusted p value:  0 ***SIGNIFICANT*** #>  #> Investigating cause(s) of significance #>  #> Null Hypothesis 1: PLR1 = PLR2 #> Test statistic:  5.246279  Adjusted p value:  1.915603e-07 ***SIGNIFICANT*** #>  #> Null Hypothesis 2: NLR1 = NLR2 #> Test statistic:  44.83283  Adjusted p value:  0 ***SIGNIFICANT***"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"flexible-input","dir":"Articles","previous_headings":"Using the compareR function","what":"Flexible input","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"compareR() function accept data data frame matrix range coding options positive negative results, detailed . working across multiple sites find researchers used different coding systems, problem! long positive results coded using something positive list negative results something negative list compareR() handle . manually re-coding data! “pesky trailing spaces?” hear ask. course, compareR() can handle , . “Case-sensitivity?” Taken care . POSITIVE: positive, pos, p, yes, y, true, t, +, 1 NEGATIVE: negative, neg, , n, false, f, -, 0, 2 two things compareR() handle. Firstly, imperative data structure provided three columns columns follow pattern Test 1, Test 2, gold standard. place gold standard index your_data[,3] compareR() may return result looks sensible answer question wanted ask. Finally, compareR() handle missing data. Removing missing data option, consider data missing don’t omit write-results. Alternatively, data missing random, consider use imputation methods replace missing data. data missing random imputation becomes vastly complex probably seek expert advice.","code":"# create data frame with varied coding df <- data.frame(   test1 = c(\" positive \", \"POS \", \" n \", \"N \", \" 1 \", \"+\"),   test2 = c(\" NEG \", \" yes \", \" negative\", \" Y \", \"-\", \" 0 \"),   gold = c(0, 1, 0, 1, 2, 1) )  # recode the dataframe recoded <- testCompareR:::recoder(df) recoded #>   test1 test2 gold #> 1     1     0    0 #> 2     1     1    1 #> 3     0     0    0 #> 4     0     1    1 #> 5     1     0    0 #> 6     1     0    1"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"variable-alpha","dir":"Articles","previous_headings":"Using the compareR function","what":"Variable alpha","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"’re using testCompareR ’re statistically savvy want nice function probably just leave alpha alone. good reason, ’re just messing around, feel free change whatever ’d like, though.","code":"# simulate data test1 <- c(rep(1, 300), rep(0, 100), rep(1, 65), rep(0, 135)) test2 <- c(rep(1, 280), rep(0, 120), rep(1, 55), rep(0, 145)) gold <- c(rep(1, 400), rep(0, 200))  df <- data.frame(test1, test2, gold)  # test with alpha = 0.5 result <- compareR(df, alpha = 0.5)  # all results are significant interpretR(result) #>  #> WARNING: #> Zeros exist in contingency table. Tests may return NA/NaN. #>  #> -------------------------------------------------------------------------------- #> CONTINGENCY TABLES #> -------------------------------------------------------------------------------- #>  #> True Status - POSITIVE #>           Test 2 #> Test 1     Positive Negative #>   Positive      280       20 #>   Negative        0      100 #>  #> True Status - NEGATIVE #>           Test 2 #> Test 1     Positive Negative #>   Positive       55       10 #>   Negative        0      135 #>  #> -------------------------------------------------------------------------------- #> PREVALENCE (%) #> -------------------------------------------------------------------------------- #>  #>            Estimate  SE Lower CI Upper CI #> Prevalence     66.7 1.9     62.8     70.3 #>  #> -------------------------------------------------------------------------------- #> DIAGNOSTIC ACCURACIES #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>             Estimate  SE Lower CI Upper CI #> Sensitivity     75.0 2.2     73.5     76.4 #> Specificity     67.5 3.3     65.2     69.7 #>  #>  Test 2 (%) #>             Estimate  SE Lower CI Upper CI #> Sensitivity     70.0 2.3     68.4     71.5 #> Specificity     72.5 3.2     70.3     74.6 #>  #> Global Null Hypothesis: Se1 = Se2 & Sp1 = Sp2 #> Test statistic:  31.57895  Adjusted p value:  4.167158e-07 ***SIGNIFICANT*** #>  #> Investigating cause(s) of significance #>  #> Null Hypothesis 1: Se1 = Se2 #> Test statistic:  18.05  Adjusted p value:  0.0001506251 ***SIGNIFICANT*** #>  #> Null Hypothesis 2: Sp1 = Sp2 #> Test statistic:  8.1  Adjusted p value:  0.02213263 ***SIGNIFICANT*** #>  #> -------------------------------------------------------------------------------- #> PREDICTIVE VALUES #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>     Estimate  SE Lower CI Upper CI #> PPV     82.2 2.0     80.8     83.5 #> NPV     57.4 3.2     55.3     59.6 #>  #>  Test 2 (%) #>     Estimate  SE Lower CI Upper CI #> PPV     83.6 2.0     82.2     84.9 #> NPV     54.7 3.1     52.6     56.8 #>  #> Global Null Hypothesis: PPV1 = PPV2 & NPV1 = NPV2 #> Test statistic:  26.92232  Adjusted p value:  2.850504e-06 ***SIGNIFICANT*** #>  #> Investigating cause(s) of significance #>  #> Null Hypothesis 1: PPV1 = PPV2 #> Test statistic:  3.171214  Adjusted p value:  0.1498935 ***SIGNIFICANT*** #>  #> Null Hypothesis 2: NPV1 = NPV2 #> Test statistic:  5.653882  Adjusted p value:  0.06966709 ***SIGNIFICANT*** #>  #> -------------------------------------------------------------------------------- #> LIKELIHOOD RATIOS #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>     Estimate  SE Lower CI Upper CI #> PLR      2.3 0.2      2.1      2.5 #> NLR      0.4 0.0      0.3      0.4 #>  #>  Test 2 (%) #>     Estimate  SE Lower CI Upper CI #> PLR      2.5 0.3      2.3      2.7 #> NLR      0.4 0.0      0.4      0.4 #>  #> Global Null Hypothesis: PLR1 = PLR2 & NLR1 = NLR2 #> Test statistic:  23.37068  Adjusted p value:  8.416292e-06 ***SIGNIFICANT*** #>  #> Investigating cause(s) of significance #>  #> Null Hypothesis 1: PLR1 = PLR2 #> Test statistic:  1.779904  Adjusted p value:  0.1498935 ***SIGNIFICANT*** #>  #> Null Hypothesis 2: NLR1 = NLR2 #> Test statistic:  2.375766  Adjusted p value:  0.06966709 ***SIGNIFICANT***"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"margins","dir":"Articles","previous_headings":"Using the compareR function","what":"Margins","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"Contingency tables included readout compareR() interpretR. people like see summed totals columns rows. ’re one people, set margins = TRUE.","code":"# simulate data test1 <- c(rep(1, 300), rep(0, 100), rep(1, 65), rep(0, 135)) test2 <- c(rep(1, 280), rep(0, 120), rep(1, 55), rep(0, 145)) gold <- c(rep(1, 400), rep(0, 200))  df <- data.frame(test1, test2, gold)  # test with alpha = 0.5 result <- compareR(df, margins = TRUE)  # contingency tables have margins result$cont #> $`True Status: POS` #>           Test 2 #> Test 1     Positive Negative Sum #>   Positive      280       20 300 #>   Negative        0      100 100 #>   Sum           280      120 400 #>  #> $`True Status: NEG` #>           Test 2 #> Test 1     Positive Negative Sum #>   Positive       55       10  65 #>   Negative        0      135 135 #>   Sum            55      145 200"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"multiple-testing","dir":"Articles","previous_headings":"Using the compareR function","what":"Multiple testing","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"default compareR() runs minimum three hypothesis tests can perform nine. accounted using adjusted p-values according Holm method. ’d prefer use different method, ’s problem. Just set multi_corr parameter methods handled base R function p.adjust().","code":"# display p.adjust.methods p.adjust.methods #> [1] \"holm\"       \"hochberg\"   \"hommel\"     \"bonferroni\" \"BH\"         #> [6] \"BY\"         \"fdr\"        \"none\"  # simulate data test1 <- c(rep(1, 300), rep(0, 100), rep(1, 65), rep(0, 135)) test2 <- c(rep(1, 280), rep(0, 120), rep(1, 55), rep(0, 145)) gold <- c(rep(1, 400), rep(0, 200))  df <- data.frame(test1, test2, gold)  # test with different multiple comparison methods result1 <- compareR(df, multi_corr = \"holm\") result2 <- compareR(df, multi_corr = \"bonf\")  # the more restrictive Bonferroni method returns higher adjusted p values result1$pv$glob.p.adj < result2$pv$glob.p.adj #> [1] TRUE"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"continuity-correction","dir":"Articles","previous_headings":"Using the compareR function","what":"Continuity correction","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"certain circumstances compareR() uses McNemar’s test testing differences diagnostic accuracies. test routinely performed continuity correction. wish perform without continuity correction set cc = FALSE. aren’t sure whether run test without continuity correction, stick default parameters.","code":"# simulate data test1 <- c(rep(1, 6), rep(0, 2), rep(1, 14), rep(0, 76)) test2 <- c(rep(1, 1), rep(0, 7), rep(1, 2), rep(0, 88)) gold <- c(rep(1, 8), rep(0, 90))  df <- data.frame(test1, test2, gold)  # run compareR without continuity correction result <- compareR(df, cc = FALSE) result$acc #> $accuracies #> $accuracies$`Test 1` #>             Estimate   SE Lower CI Upper CI #> Sensitivity     75.0 15.3     41.5     93.4 #> Specificity     84.4  3.8     75.7     90.6 #>  #> $accuracies$`Test 2` #>             Estimate   SE Lower CI Upper CI #> Sensitivity     12.5 11.7      1.4     46.2 #> Specificity     97.8  1.6     92.4     99.5 #>  #>  #> $glob.test.stat #> [1] \"n < 100 and prevalence <= 10% - global test not used\" #>  #> $glob.p.value #> [1] NA #>  #> $glob.p.adj #> [1] NA #>  #> $sens.test.stat #> [1] 13.33333 #>  #> $sens.p.value #> [1] 0.0002607296 #>  #> $sens.p.adj #> [1] 0.0003968048 #>  #> $spec.test.stat #> [1] 13.84615 #>  #> $spec.p.value #> [1] 0.0001984024 #>  #> $spec.p.adj #> [1] 0.0003968048"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"decimal-places","dir":"Articles","previous_headings":"Using the compareR function","what":"Decimal places","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"can change number decimal places displayed summary tables output compareR() interpretR() functions dp parameter. parameter affect number decimal places displayed p values test statistics.","code":"# simulate data test1 <- c(rep(1, 317), rep(0, 83), rep(1, 68), rep(0, 132)) test2 <- c(rep(1, 281), rep(0, 119), rep(1, 51), rep(0, 149)) gold <- c(rep(1, 390), rep(0, 210))  df <- data.frame(test1, test2, gold)  # test with different multiple comparison methods result <- compareR(df, dp = 3)  # the values in the summary tables are displayed to 3 decimal places result$acc$accuracies #> $`Test 1` #>             Estimate    SE Lower CI Upper CI #> Sensitivity   81.282 1.975   77.135   84.863 #> Specificity   67.619 3.229   61.046   73.605 #>  #> $`Test 2` #>             Estimate    SE Lower CI Upper CI #> Sensitivity   72.051 2.272   67.415   76.289 #> Specificity   75.714 2.959   69.520   81.052"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"choosing-your-tests","dir":"Articles","previous_headings":"Using the compareR function","what":"Choosing your tests","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"Another important aspect testCompareR package ability control study design. example, made priori decision interested predictive values, really necessary control multiple tests diagnostic accuracies likelihood ratios? course ! can ask compareR() display results setting parameters pairs tests aren’t interest FALSE. parameters follows: sesp diagnostic accuracies; ppvnpv predictive values; plrnlr likelihood ratios.","code":"# simulate data test1 <- c(rep(1, 317), rep(0, 83), rep(1, 68), rep(0, 132)) test2 <- c(rep(1, 281), rep(0, 119), rep(1, 51), rep(0, 149)) gold <- c(rep(1, 390), rep(0, 210))  df <- data.frame(test1, test2, gold)  # only display results for predictive values result <- compareR(df, sesp = FALSE, plrnlr = FALSE) result #> $cont #> $cont$`True Status: POS` #>           Test 2 #> Test 1     Positive Negative #>   Positive      281       36 #>   Negative        0       73 #>  #> $cont$`True Status: NEG` #>           Test 2 #> Test 1     Positive Negative #>   Positive       51       17 #>   Negative        0      142 #>  #>  #> $prev #>            Estimate  SE Lower CI Upper CI #> Prevalence       65 1.9     61.1     68.7 #>  #> $pv #> $pv$predictive.values #> $pv$predictive.values$`Test 1` #>     Estimate  SE Lower CI Upper CI #> PPV     82.3 1.9     78.2     85.8 #> NPV     66.0 3.2     59.5     72.1 #>  #> $pv$predictive.values$`Test 2` #>     Estimate SE Lower CI Upper CI #> PPV     84.6  2     80.4     88.1 #> NPV     59.3  3     53.4     65.0 #>  #>  #> $pv$glob.test.stat #> [1] 50.21468 #>  #> $pv$glob.p.value #> [1] 1.247447e-11 #>  #> $pv$glob.p.adj #> [1] 1.247447e-11 #>  #> $pv$ppv.test.stat #> [1] 5.279658 #>  #> $pv$ppv.p.value #> [1] 0.02157598 #>  #> $pv$ppv.p.adj #> [1] 0.02157598 #>  #> $pv$npv.test.stat #> [1] 15.86226 #>  #> $pv$npv.p.value #> [1] 6.812387e-05 #>  #> $pv$npv.p.adj #> [1] 0.0001362477 #>  #>  #> $other #> $other$alpha #> [1] 0.05 #>  #> $other$equal #> [1] FALSE #>  #> $other$zeros #> [1] 2 #>  #> $other$Youden1 #> [1] 0.489011 #>  #> $other$Youden2 #> [1] 0.4776557 #>  #> $other$test.names #> [1] \"Test 1\" \"Test 2\" #>  #>  #> attr(,\"class\") #> [1] \"compareR\""},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"test-names","dir":"Articles","previous_headings":"Using the compareR function","what":"Test names","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"want specific test names included output compareR() can set test.names parameter. parameter accepts character vector length 2.","code":"# simulate data test1 <- c(rep(1, 317), rep(0, 83), rep(1, 68), rep(0, 132)) test2 <- c(rep(1, 281), rep(0, 119), rep(1, 51), rep(0, 149)) gold <- c(rep(1, 390), rep(0, 210))  df <- data.frame(test1, test2, gold)  # only display results for predictive values result <- compareR(df, test.names = c(\"POCT\", \"Lab Blood\")) result$acc$accuracies #> $POCT #>             Estimate  SE Lower CI Upper CI #> Sensitivity     81.3 2.0     77.1     84.9 #> Specificity     67.6 3.2     61.0     73.6 #>  #> $`Lab Blood` #>             Estimate  SE Lower CI Upper CI #> Sensitivity     72.1 2.3     67.4     76.3 #> Specificity     75.7 3.0     69.5     81.1"},{"path":"https://kajlinko.github.io/testCompareR/articles/using_testCompareR.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Comparing binary diagnostic tests from paired data using testCompareR","text":"made end! pretty well summarises everything need know package. Hopefully save lot time comparing two binary diagnostic tests. Please get touch refinements, comments bugs. source code available Github think can improve !","code":""},{"path":"https://kajlinko.github.io/testCompareR/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Kyle J. Wilson. Maintainer, author. Marc Henrion. Author. José Antonio Roldán Nofuentes. Author.","code":""},{"path":"https://kajlinko.github.io/testCompareR/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Wilson K, Henrion M, Roldán Nofuentes J (2023). testCompareR: Comparing Two Diagnostic Tests Dichotomous Results using Paired Data. R package version 1.0.2, https://kajlinko.github.io/testCompareR/.","code":"@Manual{,   title = {testCompareR: Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data},   author = {Kyle J. Wilson and Marc Henrion and José Antonio {Roldán Nofuentes}},   year = {2023},   note = {R package version 1.0.2},   url = {https://kajlinko.github.io/testCompareR/}, }"},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"testcomparer","dir":"","previous_headings":"","what":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"Test metrics like sensitivity, specificity, predictive values likelihood ratios common ways measure performance diagnostic test. goal testCompareR make comparing test metrics two diagnostic tests dichotomous outcomes easy. Really easy. want clinical researchers able quickly access statistical methods best performance, without trawl literature learn new complicated package. testCompareR don’t .","code":""},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"can install development version testCompareR GitHub :","code":"install.packages(\"devtools\") devtools::install_github(\"Kajlinko/testCompareR\")"},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"examples","dir":"","previous_headings":"","what":"Examples","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"testCompareR two principal functions: compareR() interpretR. example simulated data demonstrates work. data provided data frame matrix three columns order test1, test2 gold. sensible code positive negative results systematically, real research can sometimes messy. compareR() function try take care . two function calls can calculate test metrics, including confidence intervals best coverage, compare test metrics using hypothesis tests best asymptotic performance. interpretR() even provides plain English summary results mean console.","code":"library(testCompareR)  # simulate some data test1 <- rep(c(\"positive\", \"pos\", \"p\", \"yes\", \"y\", \"+\", \"1\"), 10) test2 <- rep(c(\"negative\", \"neg\", \"no\", \"n\", \"-\", \"0\", \"2\"), 10) gold <- rep(c(\"positive\", \"pos\", \"p\", \"yes\", \"y\", \"+\", \"1\"), 10)  df <- data.frame(test1, test2, gold)  # run the tests results <- compareR(df)  # interpret the results (optional) interpretR <- results"},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"additional-functions","dir":"","previous_headings":"Examples","what":"Additional functions","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"one test gold standard can summarise descriptive statistics quickly summariseR(). data presented data frame matrix two columns. One final function defined help clinical researchers want perform pooled meta-analysis data already available. dataframeR() constructs data frame can provided compareR() figures commonly quoted literature. dataframeR() eight parameters: s11, s10, s01, s00, r11, r10, r01, r00. Understanding parameter names: s & r represent positive negative results gold standard test, respectively. first digit represents positive (1) negative (0) result Test 1. second digit represents positive (1) negative (0) result Test 2. data frame can combined data frames produce master data frame ready analysis. ideas additional functionalities think added, please get touch , better still, make pull request see can code.","code":"library(testCompareR)  # simulate some data test1 <- rep(c(\"positive\", \"pos\", \"p\", \"yes\", \"y\", \"+\", \"1\"), 10) gold <- rep(c(\"positive\", \"pos\", \"p\", \"yes\", \"y\", \"+\", \"1\"), 10)  df <- data.frame(test1, gold)  # run the tests summariseR(df) dataframeR(70, 5, 11, 40, 11, 2, 3, 120)"},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"contributors","dir":"","previous_headings":"","what":"Contributors","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"project helped greatly Marc Henrion GitHub. Additionally, statistical methods underlying package source code upon based provided José Antonio Roldán Nofuentes. use package, please consider referencing paper describing statistical methods. paper available .","code":""},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"work licensed General Public License v3.0 (2007). See LICENSE.md details.","code":""},{"path":"https://kajlinko.github.io/testCompareR/index.html","id":"references","dir":"","previous_headings":"","what":"References","title":"Comparing Two Diagnostic Tests with Dichotomous Results using Paired Data","text":"Yu, Guo & Xu (2014) JSCS. 2014; 84:5,1022-1038 doi:10.1080/00949655.2012.738211 Martín Andrés & Álvarez Hernández (2014) Stat Comput. 2014; 24,65–75 doi:10.1007/s11222-012-9353-5 Roldán-Nofuentes & Sidaty-Regad (2019) JSCS. 2019; 89:14,2621-2644 doi:10.1080/00949655.2019.1628234 Roldán-Nofuentes, Luna del Castillo & Montero-Alonso (2012) Comput Stat Data Anal. 2012; 6,1161–1173. doi:10.1016/j.csda.2011.06.003 Kosinski (2012) Stat Med. 2012; 32,964-977 doi:10.1002/sim.5587 Roldán-Nofuentes, Luna del Castillo (2007) Stat Med. 2007; 26:4179–201. doi:10.1002/sim.2850 Roldán-Nofuentes (2020) BMC Med Res Methodol. 2020; 20,143 doi:10.1186/s12874-020-00988-y","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cass.html","id":null,"dir":"Reference","previous_headings":"","what":"Coronary Artery Surgery Study data — cass","title":"Coronary Artery Surgery Study data — cass","text":"data Coronary Artery Surgery Study evaluates two tests determine presence absence coronary artery disease comparing coronary angiography, gold standard. Test 1 exercise stress test Test 2 clinical history chest pain.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cass.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coronary Artery Surgery Study data — cass","text":"","code":"cass"},{"path":"https://kajlinko.github.io/testCompareR/reference/cass.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Coronary Artery Surgery Study data — cass","text":"data frame 871 rows 3 columns: exercise Dichotomous result exercise stress testing. cp Presence absence chest pain based medical history. angio Dichotomous result coronary angiography.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cass.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Coronary Artery Surgery Study data — cass","text":"doi:10.1056/NEJM197908023010502","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cass.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Coronary Artery Surgery Study data — cass","text":"three variables dichotomous. 1 indicates positive result; 0 indicates negative result. data originally presented Weiner et al. (1979).","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cass.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Coronary Artery Surgery Study data — cass","text":"Weiner et al. (1979)) N Engl J Med. 1979;301(5):230-5 doi:10.1056/NEJM197908023010502","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cfpr.html","id":null,"dir":"Reference","previous_headings":"","what":"US Cystic Fibrosis Patient Registry data — cfpr","title":"US Cystic Fibrosis Patient Registry data — cfpr","text":"data Cystic Fibrosis Foundation's Patient Registry (USA) evaluates risk factors pulmonary exacerbation patients cystic fibrosis. two risk factors evaluated previous pulmonary exacerbation previous colonisation Pseudomonas aeruginosa. two risk factors evaluated using data 1995. instance occurred point 1995 'test' considered positive. negative throughout 1995 'test' considered negative. gold standard evidence pulmonary exacerbation point 1996.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cfpr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"US Cystic Fibrosis Patient Registry data — cfpr","text":"","code":"cfpr"},{"path":"https://kajlinko.github.io/testCompareR/reference/cfpr.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"US Cystic Fibrosis Patient Registry data — cfpr","text":"data frame 11,960 rows 3 columns: pulm.exac Presence absence previous pulmonary exacerbation. pseudomonas Presence absence Pseudomonas aeruginosa   infection. infection Presence absence severe infection (gold standard).","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cfpr.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"US Cystic Fibrosis Patient Registry data — cfpr","text":"Data sourced directly referenced paper. --date data requests contact: Cystic Fibrosis Foundation","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cfpr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"US Cystic Fibrosis Patient Registry data — cfpr","text":"three variables dichotomous. 1 indicates presence; 0 indicates absence. data originally presented Moskowitz Pepe (2006).","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/cfpr.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"US Cystic Fibrosis Patient Registry data — cfpr","text":"Moskowitz Pepe (2006) Clinical Trials. 2006;3(3):272-9. doi:10.1191/1740774506cn147oa","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":null,"dir":"Reference","previous_headings":"","what":"compareR — compareR","title":"compareR — compareR","text":"Calculates descriptive statistics performs statistical inference two binary diagnostic tests single function call. Handles multiple comparisons using methods `p.adjust()`.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"compareR — compareR","text":"","code":"compareR(   df,   alpha = 0.05,   margins = FALSE,   multi_corr = \"holm\",   cc = TRUE,   dp = 1,   sesp = TRUE,   ppvnpv = TRUE,   plrnlr = TRUE,   test.names = c(\"Test 1\", \"Test 2\"),   ... )"},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"compareR — compareR","text":"df data frame matrix 3 columns (test1, test2, gold). Flexible coding positive negative results permitted. alpha alpha value. Defaults 0.05. margins Boolean value indicating whether contingency tables margins containing summed totals rows columns. multi_corr Method multiple comparisons. Uses `p.adjust.methods`. cc Boolean value indicating whether McNemar's test applied continuity correction. dp Number decimal places output summary tables. Defaults 1. sesp Boolean value indicating whether output include sensitivity specificity. ppvnpv Boolean value indicating whether output include positive negative predictive values. plrnlr Boolean value indicating whether output include positive negative likelihood ratios. test.names vector length two giving names two different binary diagnostic tests. argument relevant testing single binary diagnostic test. ... Rarely needs used. Allows additional arguments passed internal functions.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"compareR — compareR","text":"list object summarising calculated descriptive inferential statistics.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"compareR — compareR","text":"Confidence intervals prevalence, diagnostic accuracies predictive values calculated using interval binomial proportions described Yu et al. (2014). Confidence intervals likelihood ratios calculated using methods recommended Martín-Andrés Álvarez-Hernández (2014). Hypothesis testing diagnostic accuracies uses different methods depending disease prevalence number participants samples described Roldán-Nofuentes Sidaty-Regad (2019). Global hypothesis testing predictive values uses method described Roldán-Nofuentes et al. (2012), subsequent individual tests (indicated) performed using methods described Kosinksi (2012). methods hypothesis testing- likelihood ratios taken Roldán-Nofuentes & Luna del Castillo (2007). excellent summary methods provided Roldán-Nofuentes (2020) along open-source program (compbdt) licensed GPL-2. R package can considered extension work therefore distributed license. Please consider citing Roldán-Nofuentes (2020) citing package.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"compareR — compareR","text":"Yu, Guo & Xu (2014) JSCS. 2014; 84:5,1022-1038 doi:10.1080/00949655.2012.738211 Martín Andrés & Álvarez Hernández (2014) Stat Comput. 2014; 24,65–75 doi:10.1007/s11222-012-9353-5 Roldán-Nofuentes & Sidaty-Regad (2019) JSCS. 2019; 89:14,2621-2644 doi:10.1080/00949655.2019.1628234 Roldán-Nofuentes, Luna del Castillo & Montero-Alonso (2012) Comput Stat Data Anal. 2012; 6,1161–1173. doi:10.1016/j.csda.2011.06.003 Kosinski (2012) Stat Med. 2012; 32,964-977 doi:10.1002/sim.5587 Roldán-Nofuentes, Luna del Castillo (2007) Stat Med. 2007; 26:4179–201. doi:10.1002/sim.2850 Roldán-Nofuentes (2020) BMC Med Res Methodol. 2020; 20,143 doi:10.1186/s12874-020-00988-y","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/compareR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"compareR — compareR","text":"","code":"# load data df <- cfpr  # run compareR function compareR(df,   margins = TRUE, multi_corr = \"bonf\",   test.names = c(\"pulm.exac\", \"pseudomonas\") ) #> $cont #> $cont$`True Status: POS` #>           Test 2 #> Test 1     Positive Negative  Sum #>   Positive      185     3445 3630 #>   Negative        0     1424 1424 #>   Sum           185     4869 5054 #>  #> $cont$`True Status: NEG` #>           Test 2 #> Test 1     Positive Negative  Sum #>   Positive      123     1219 1342 #>   Negative        0     5564 5564 #>   Sum           123     6783 6906 #>  #>  #> $prev #>            Estimate  SE Lower CI Upper CI #> Prevalence     42.3 0.5     41.4     43.1 #>  #> $acc #> $acc$accuracies #> $acc$accuracies$pulm.exac #>             Estimate  SE Lower CI Upper CI #> Sensitivity     71.8 0.6     70.6     73.0 #> Specificity     80.6 0.5     79.6     81.5 #>  #> $acc$accuracies$pseudomonas #>             Estimate  SE Lower CI Upper CI #> Sensitivity      3.7 0.3      3.2      4.2 #> Specificity     98.2 0.2     97.9     98.5 #>  #>  #> $acc$glob.test.stat #> [1] 12301.32 #>  #> $acc$glob.p.value #> [1] 0 #>  #> $acc$glob.p.adj #> [1] 0 #>  #> $acc$sens.test.stat #> [1] 10821.03 #>  #> $acc$sens.p.value #> [1] 0 #>  #> $acc$sens.p.adj #> [1] 0 #>  #> $acc$spec.test.stat #> [1] 1480.291 #>  #> $acc$spec.p.value #> [1] 0 #>  #> $acc$spec.p.adj #> [1] 0 #>  #>  #> $pv #> $pv$predictive.values #> $pv$predictive.values$pulm.exac #>     Estimate  SE Lower CI Upper CI #> PPV     73.0 0.6     71.8     74.2 #> NPV     79.6 0.5     78.7     80.6 #>  #> $pv$predictive.values$pseudomonas #>     Estimate  SE Lower CI Upper CI #> PPV     60.1 2.8     54.5     65.4 #> NPV     58.2 0.5     57.3     59.1 #>  #>  #> $pv$glob.test.stat #> [1] 2830.026 #>  #> $pv$glob.p.value #> [1] 0 #>  #> $pv$glob.p.adj #> [1] 0 #>  #> $pv$ppv.test.stat #> [1] 28.45746 #>  #> $pv$ppv.p.value #> [1] 9.578013e-08 #>  #> $pv$ppv.p.adj #> [1] 7.66241e-07 #>  #> $pv$npv.test.stat #> [1] 2261.186 #>  #> $pv$npv.p.value #> [1] 0 #>  #> $pv$npv.p.adj #> [1] 0 #>  #>  #> $lr #> $lr$likelihood.ratios #> $lr$likelihood.ratios$pulm.exac #>     Estimate  SE Lower CI Upper CI #> PLR      3.7 0.1      3.5      3.9 #> NLR      0.3 0.0      0.3      0.4 #>  #> $lr$likelihood.ratios$pseudomonas #>     Estimate  SE Lower CI Upper CI #> PLR      2.1 0.2      1.6      2.6 #> NLR      1.0 0.0      1.0      1.0 #>  #>  #> $lr$glob.test.stat #> [1] 2010.219 #>  #> $lr$glob.p.value #> [1] 0 #>  #> $lr$glob.p.adj #> [1] 0 #>  #> $lr$plr.test.stat #> [1] 5.246279 #>  #> $lr$plr.p.value #> [1] 1.552014e-07 #>  #> $lr$plr.p.adj #> [1] 1.241611e-06 #>  #> $lr$nlr.test.stat #> [1] 44.83283 #>  #> $lr$nlr.p.value #> [1] 0 #>  #> $lr$nlr.p.adj #> [1] 0 #>  #>  #> $other #> $other$alpha #> [1] 0.05 #>  #> $other$equal #> [1] FALSE #>  #> $other$zeros #> [1] 2 #>  #> $other$Youden1 #> [1] 0.5239192 #>  #> $other$Youden2 #> [1] 0.01879407 #>  #> $other$test.names #> [1] \"pulm.exac\"   \"pseudomonas\" #>  #>  #> attr(,\"class\") #> [1] \"compareR\""},{"path":"https://kajlinko.github.io/testCompareR/reference/dataframeR.html","id":null,"dir":"Reference","previous_headings":"","what":"dataframeR — dataframeR","title":"dataframeR — dataframeR","text":"Produces data frame can used compareR function using values commonly found published literature. Useful reviews meta-analyses.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/dataframeR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"dataframeR — dataframeR","text":"","code":"dataframeR(s11, s10, s01, s00, r11, r10, r01, r00)"},{"path":"https://kajlinko.github.io/testCompareR/reference/dataframeR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"dataframeR — dataframeR","text":"s11 Number cases Test 1 positive, Test 2 positive gold standard positive. s10 Number cases Test 1 positive, Test 2 negative gold standard positive. s01 Number cases Test 1 negative, Test 2 positive gold standard positive. s00 Number cases Test 1 negative, Test 2 negative gold standard positive. r11 Number cases Test 1 positive, Test 2 positive gold standard negative. r10 Number cases Test 1 positive, Test 2 negative gold standard negative. r01 Number cases Test 1 negative, Test 2 positive gold standard negative. r00 Number cases Test 1 negative, Test 2 negative gold standard negative.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/dataframeR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"dataframeR — dataframeR","text":"data frame populated zeros ones indicating positive negative test results can passed compareR function.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/dataframeR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"dataframeR — dataframeR","text":"Understanding parameter names: s & r represent positive negative results gold standard test, respectively. first digit represents positive (1) negative (0) result Test 1. second digit represents positive (1) negative (0) result Test 2.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/dataframeR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"dataframeR — dataframeR","text":"","code":"# build data frame using numbers dataframeR(3, 3, 3, 3, 3, 3, 3, 3) #>    test1 test2 gold #> 1      1     1    1 #> 2      1     1    1 #> 3      1     1    1 #> 4      1     0    1 #> 5      1     0    1 #> 6      1     0    1 #> 7      0     1    1 #> 8      0     1    1 #> 9      0     1    1 #> 10     0     0    1 #> 11     0     0    1 #> 12     0     0    1 #> 13     1     1    0 #> 14     1     1    0 #> 15     1     1    0 #> 16     1     0    0 #> 17     1     0    0 #> 18     1     0    0 #> 19     0     1    0 #> 20     0     1    0 #> 21     0     1    0 #> 22     0     0    0 #> 23     0     0    0 #> 24     0     0    0"},{"path":"https://kajlinko.github.io/testCompareR/reference/interpretR.html","id":null,"dir":"Reference","previous_headings":"","what":"interpretR — interpretR","title":"interpretR — interpretR","text":"Provides plain English readout results compareR function.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/interpretR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"interpretR — interpretR","text":"","code":"interpretR(result)"},{"path":"https://kajlinko.github.io/testCompareR/reference/interpretR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"interpretR — interpretR","text":"result list object class 'compareR' output compareR function.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/interpretR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"interpretR — interpretR","text":"plain English summary findings produced compareR function.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/interpretR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"interpretR — interpretR","text":"","code":"# simulate data test1 <- c(rep(1, 300), rep(0, 100), rep(1, 55), rep(0, 145)) test2 <- c(rep(1, 280), rep(0, 120), rep(1, 45), rep(0, 155)) gold <- c(rep(1, 400), rep(0, 200)) dat <- data.frame(test1, test2, gold)  # compare with compareR result <- compareR(dat)  # provide a plain English readout with interpretR interpretR(result) #>  #> WARNING: #> Zeros exist in contingency table. Tests may return NA/NaN. #>  #> -------------------------------------------------------------------------------- #> CONTINGENCY TABLES #> -------------------------------------------------------------------------------- #>  #> True Status - POSITIVE #>           Test 2 #> Test 1     Positive Negative #>   Positive      280       20 #>   Negative        0      100 #>  #> True Status - NEGATIVE #>           Test 2 #> Test 1     Positive Negative #>   Positive       45       10 #>   Negative        0      145 #>  #> -------------------------------------------------------------------------------- #> PREVALENCE (%) #> -------------------------------------------------------------------------------- #>  #>            Estimate  SE Lower CI Upper CI #> Prevalence     66.7 1.9     62.8     70.3 #>  #> -------------------------------------------------------------------------------- #> DIAGNOSTIC ACCURACIES #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>             Estimate  SE Lower CI Upper CI #> Sensitivity     75.0 2.2     70.5     79.0 #> Specificity     72.5 3.2     66.0     78.3 #>  #>  Test 2 (%) #>             Estimate  SE Lower CI Upper CI #> Sensitivity     70.0 2.3     65.4     74.3 #> Specificity     77.5 3.0     71.3     82.8 #>  #> Global Null Hypothesis: Se1 = Se2 & Sp1 = Sp2 #> Test statistic:  31.57895  Adjusted p value:  4.167158e-07 ***SIGNIFICANT*** #>  #> Investigating cause(s) of significance #>  #> Null Hypothesis 1: Se1 = Se2 #> Test statistic:  18.05  Adjusted p value:  0.0001506251 ***SIGNIFICANT*** #>  #> Null Hypothesis 2: Sp1 = Sp2 #> Test statistic:  8.1  Adjusted p value:  0.02213263 ***SIGNIFICANT*** #>  #> -------------------------------------------------------------------------------- #> PREDICTIVE VALUES #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>     Estimate  SE Lower CI Upper CI #> PPV     84.5 1.9     80.4     87.9 #> NPV     59.2 3.1     52.9     65.2 #>  #>  Test 2 (%) #>     Estimate  SE Lower CI Upper CI #> PPV     86.2 1.9     82.0     89.5 #> NPV     56.4 3.0     50.5     62.1 #>  #> Global Null Hypothesis: PPV1 = PPV2 & NPV1 = NPV2 #> Test statistic:  28.43169  Adjusted p value:  1.340192e-06 ***SIGNIFICANT*** #>  #> Investigating cause(s) of significance #>  #> Null Hypothesis 1: PPV1 = PPV2 #> Test statistic:  4.059529  Adjusted p value:  0.08784551 #>  #> Null Hypothesis 2: NPV1 = NPV2 #> Test statistic:  6.343355  Adjusted p value:  0.04712873 ***SIGNIFICANT*** #>  #> -------------------------------------------------------------------------------- #> LIKELIHOOD RATIOS #> -------------------------------------------------------------------------------- #>  #>  Test 1 (%) #>     Estimate  SE Lower CI Upper CI #> PLR      2.7 0.3      2.2      3.5 #> NLR      0.3 0.0      0.3      0.4 #>  #>  Test 2 (%) #>     Estimate  SE Lower CI Upper CI #> PLR      3.1 0.4      2.4      4.1 #> NLR      0.4 0.0      0.3      0.5 #>  #> Global Null Hypothesis: PLR1 = PLR2 & NLR1 = NLR2 #> Test statistic:  24.2216  Adjusted p value:  5.499788e-06 ***SIGNIFICANT*** #>  #> Investigating cause(s) of significance #>  #> Null Hypothesis 1: PLR1 = PLR2 #> Test statistic:  2.013107  Adjusted p value:  0.08784551 #>  #> Null Hypothesis 2: NLR1 = NLR2 #> Test statistic:  2.516314  Adjusted p value:  0.04712873 ***SIGNIFICANT***"},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":null,"dir":"Reference","previous_headings":"","what":"summariseR — summariseR","title":"summariseR — summariseR","text":"Summarises descriptive statistics associated single binary diagnostic test.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"summariseR — summariseR","text":"","code":"summariseR(df, dp = 1)"},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"summariseR — summariseR","text":"df data frame matrix 2 columns (test1, gold). Flexible coding positive negative results permitted. dp Number decimal places output summary tables. Defaults 1. Kappa defaults 3 decimal places unless user selects .","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"summariseR — summariseR","text":"summary descriptive statistics binary diagnostic test, compared gold standard.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"summariseR — summariseR","text":"Confidence intervals prevalence, diagnostic accuracies predictive values calculated using interval binomial proportions described Yu et al. (2014). Confidence intervals likelihood ratios calculated using methods recommended Martín-Andrés Álvarez-Hernández (2014). Cohen's kappa value -1 1 describes agreement two tests, taking account random agreement. score zero less indicates agreement entirely due chance.","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"summariseR — summariseR","text":"Yu, Guo & Xu (2014) JSCS. 2014; 84:5,1022-1038 doi:10.1080/00949655.2012.738211 Martín Andrés & Álvarez Hernández (2014) Stat Comput. 2014; 24,65–75 doi:10.1007/s11222-012-9353-5 Cohen (1960) Educ Psychol Meas. 1960; 20(1),37–46 doi:10.1177/001316446002000104","code":""},{"path":"https://kajlinko.github.io/testCompareR/reference/summariseR.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"summariseR — summariseR","text":"","code":"# simulate data test1 <- c(rep(1, 300), rep(0, 100), rep(1, 55), rep(0, 145)) gold <- c(rep(1, 400), rep(0, 200)) dat <- data.frame(test1, gold)  # summarise descriptive statistics result <- summariseR(dat, dp = 4)"},{"path":"https://kajlinko.github.io/testCompareR/news/index.html","id":"testcomparer-102","dir":"Changelog","previous_headings":"","what":"testCompareR 1.0.2","title":"testCompareR 1.0.2","text":"CRAN release: 2023-09-15 Finalised corrections p value calculations updated package tests Changed license GPL3 conform CRAN","code":""},{"path":"https://kajlinko.github.io/testCompareR/news/index.html","id":"testcomparer-101","dir":"Changelog","previous_headings":"","what":"testCompareR 1.0.1","title":"testCompareR 1.0.1","text":"Updated Roldán-Nofuentes’ role author Updated p value calculations correct formula Updated license GPL3+ (written permission JARN)","code":""},{"path":"https://kajlinko.github.io/testCompareR/news/index.html","id":"testcomparer-100","dir":"Changelog","previous_headings":"","what":"testCompareR 1.0.0","title":"testCompareR 1.0.0","text":"CRAN release: 2023-06-27 Submitted CRAN","code":""},{"path":"https://kajlinko.github.io/testCompareR/news/index.html","id":"testcomparer-010","dir":"Changelog","previous_headings":"","what":"testCompareR 0.1.0","title":"testCompareR 0.1.0","text":"Added NEWS.md file track changes package. Validated statistical methods alternatives (DTComPair package) compbdt program Prepared submission CRAN","code":""}]
